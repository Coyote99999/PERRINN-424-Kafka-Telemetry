version: '3.8'

networks:
  kafka-network:
    driver: bridge

services:

  # Responsible for coordination and synchronization between distributed systems, such as Kafka and HBase.
  zookeeper:
    image: ubuntu/zookeeper:3.8-22.04_edge
    container_name: zookeeper
    networks:
      - kafka-network
  # Provides a web-based user interface for monitoring and managing Zookeeper clusters.
  zoonavigator:
    image: elkozmon/zoonavigator:latest
    container_name: zoonavigator
    networks:
      - kafka-network
    ports:
      - "9123:9000"
    environment:
      HTTP_PORT: 9000
      CONNECTION_LOCALZK_NAME: "Local ZooKeeper"
      CONNECTION_LOCALZK_CONN: "zookeeper:2181"
    depends_on:
      - zookeeper

 # A distributed streaming platform used for real-time data ingestion and processing.
  kafka:
    image: ubuntu/kafka:3.6-22.04_edge
    container_name: kafka
    networks:
      - kafka-network
    ports:
      - "${KAFKA_PORT}:9092"
    volumes:
      - ./kafka-server.properties:/etc/kafka/server.properties
    depends_on:
      - zookeeper

  # Offers a user interface for monitoring Kafka clusters and topics.
  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    networks:
      - kafka-network
    ports:
      - "${KAFKA_UI_PORT}:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: default
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka

  # Offers real time stream processing, as opposed to spark which is used for batch processing
  flink-jobmanager:
    build:
      context: .
      dockerfile: flinkDockerfile
    container_name: flink-jobmanager
    networks:
      - kafka-network
    ports:
      - "${FLINK_UI_PORT}:8081"
      - "${FLINK_RPC_PORT_JOBMANAGER}:6123"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager

  flink-taskmanager:
    build:
      context: .
      dockerfile: flinkDockerfile
    container_name: flink-taskmanager
    networks:
      - kafka-network
    command: taskmanager
    ports:
      - "${FLINK_RPC_PORT_TASKMANAGER}:6122"
      - "${FLINK_DATA_PORT_TASKMANAGER}:6121"
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    depends_on:
      - flink-jobmanager

  # Acts as the Spark master node, managing the allocation of resources and scheduling tasks across the Spark cluster.
  spark:
    image: bitnami/spark
    container_name: spark
    environment:
      - SPARK_MODE=master
    networks:
      - kafka-network
    ports:
      - "8088:8080"  # Spark UI
      - "7078:7077"  # Spark Master

  # A distributed NoSQL database that provides real-time read/write access to large datasets, often used for random, real-time access to big data.
  hbase:
    image: hyness/hbase-rest-standalone
    container_name: hbase
    networks:
      - kafka-network
    volumes:
      - ./hbase-site.xml:/opt/hbase/conf/hbase-site.xml  # Mount custom configuration directory
    ports:
      - "2181:2181"
      - "8080:8080"
      - "16000:16000"
      - "16010:16010" # UI port
      - "16020:16020"
      - "16030:16030"
    environment:
      - HBASE_ZOOKEEPER_QUORUM=zookeeper
      - HBASE_ZOOKEEPER_CLIENT_PORT=2181

  # Apache Hadoop Section

  # NOTE: Hadoop itself includes HDFS (Hadoop Distributed File System) as one of its core components. 
  # NOTE: When you install Hadoop, you automatically get HDFS along with it. 
  # NOTE: HDFS is the primary storage layer in the Hadoop ecosystem, providing distributed storage for large-scale data processing. 
  # NOTE: So, you don't need to separately install HDFS when setting up a Hadoop cluster; it comes bundled with the Hadoop distribution.

  # Manages the filesystem namespace and metadata for HDFS (Hadoop Distributed File System). HDFS + Hadoop are bundled together in this container
  namenode:
    image: apache/hadoop:3
    container_name: hadoop-namenode
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./hadoop-config.env
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"


  # Stores actual data blocks and serves read and write requests from clients in HDFS. HDFS + Hadoop are bundled together in this container
  datanode:
    image: apache/hadoop:3
    container_name: hadoop-datanode
    command: ["hdfs", "datanode"]
    env_file:
      - ./hadoop-config.env

  # Manages resources in the YARN (Yet Another Resource Negotiator) cluster, allocating resources to applications.
  resourcemanager:
    image: apache/hadoop:3
    container_name: hadoop-resourcemanager
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
       - 8089:8088
    env_file:
      - ./hadoop-config.env
    volumes:
      - ./test.sh:/opt/test.sh

  # Manages resources and executes tasks on individual nodes in the YARN cluster.
  nodemanager:
    image: apache/hadoop:3
    container_name: hadoop-nodemanager
    command: ["yarn", "nodemanager"]
    env_file:
      - ./hadoop-config.env

  # The holy grail of monitoring - with this we can have out real time graphs
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    networks:
      - kafka-network
    ports:
      - "3000:3000"


 # Machine Learning Tools

   # MLFlow Tracking Server to track experiments for ML
  tracking_server:
    restart: always
    build:
      context: .
      dockerfile: mlflowDockerfile
    container_name: mlflow_server
    depends_on:
      - db
      - s3
    ports:
      - "${MLFLOW_PORT}:5000"
    networks:
      - kafka-network
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:${MINIO_PORT}
      - MLFLOW_S3_IGNORE_TLS=true
    command: >
      mlflow server
      --backend-store-uri postgresql://${PG_USER}:${PG_PASSWORD}@db:${PG_PORT}/${PG_DATABASE}
      --host 0.0.0.0
      --serve-artifacts
      --artifacts-destination s3://${MLFLOW_BUCKET_NAME}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MLFLOW_PORT}/"]
      interval: 30s
      timeout: 10s
      retries: 3

  db:
    restart: always
    image: postgres
    container_name: mlflow_db
    expose:
      - "${PG_PORT}"
    networks:
      - kafka-network
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
      - POSTGRES_DATABASE=${PG_DATABASE}
    volumes:
      - ./db_data:/var/lib/postgresql/data/
    healthcheck:
      test: ["CMD", "pg_isready", "-p", "${PG_PORT}", "-U", "${PG_USER}"]
      interval: 5s
      timeout: 5s
      retries: 3

  # Now we add the pgadmin4 service so we can monitor db contents should we need to
  pgadmin4:
    image: dpage/pgadmin4:latest
    container_name: pgadmin4
    networks:
      - kafka-network
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_DEFAULT_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - "${PGADMIN4_PORT}:80"
    volumes:
      - ./pgadmin4_psql_servers.json:/pgadmin4/servers.json

  # S3 storage for MLFlow
  s3:
    restart: always
    image: minio/minio:latest
    container_name: mlflow_minio
    volumes:
      - ./minio_data:/data
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    networks:
      - kafka-network
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_ADDRESS=${MINIO_ADDRESS}
      - MINIO_PORT=${MINIO_PORT}
      - MINIO_STORAGE_USE_HTTPS=${MINIO_STORAGE_USE_HTTPS}
      - MINIO_CONSOLE_ADDRESS=${MINIO_CONSOLE_ADDRESS}
    command: server --console-address ":${MINIO_CONSOLE_PORT}" /data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  s3_mlflow_createbuckets:
    container_name: mlflow_create_bucket_job
    image: minio/mc
    depends_on:
      - s3
    networks:
      - kafka-network
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set s3minio http://s3:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      /usr/bin/mc mb s3minio/${MLFLOW_BUCKET_NAME};
      /usr/bin/mc policy set public s3minio/${MLFLOW_BUCKET_NAME};
      exit 0;
      "

  s3_mlflow_createaccesskey:
    container_name: mlflow_create_accesskey_job
    image: minio/mc
    depends_on:
      - s3
    networks:
      - kafka-network
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set s3minio http://s3:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
      /usr/bin/mc admin user svcacct add --access-key "${MINIO_ACCESS_KEY}" --secret-key "${MINIO_SECRET_ACCESS_KEY}" --name mlflow --description connection s3minio ${MINIO_ROOT_USER};
      exit 0;
      "
volumes:
  db_data:
  minio_data:
